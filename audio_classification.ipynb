{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78cda132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adityaraut/.local/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41c122ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_json('/home/adityaraut/Documents/Machine-Learning-FCC/dl_fcc/archive/Sarcasm_Headlines_Dataset.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f16d9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.dropna(inplace=True)\n",
    "data_df.drop(['article_link'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2186e7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "headline",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_sarcastic",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "f13e6060-7222-45b5-9fb7-7040e1fe2c30",
       "rows": [
        [
         "0",
         "former versace store clerk sues over secret 'black code' for minority shoppers",
         "0"
        ],
        [
         "1",
         "the 'roseanne' revival catches up to our thorny political mood, for better and worse",
         "0"
        ],
        [
         "2",
         "mom starting to fear son's web series closest thing she will have to grandchild",
         "1"
        ],
        [
         "3",
         "boehner just wants wife to listen, not come up with alternative debt-reduction ideas",
         "1"
        ],
        [
         "4",
         "j.k. rowling wishes snape happy birthday in the most magical way",
         "0"
        ],
        [
         "5",
         "advancing the world's women",
         "0"
        ],
        [
         "6",
         "the fascinating case for eating lab-grown meat",
         "0"
        ],
        [
         "7",
         "this ceo will send your kids to school, if you work for his company",
         "0"
        ],
        [
         "8",
         "top snake handler leaves sinking huckabee campaign",
         "1"
        ],
        [
         "9",
         "friday's morning email: inside trump's presser for the ages",
         "0"
        ],
        [
         "10",
         "airline passengers tackle man who rushes cockpit in bomb threat",
         "0"
        ],
        [
         "11",
         "facebook reportedly working on healthcare features and apps",
         "0"
        ],
        [
         "12",
         "north korea praises trump and urges us voters to reject 'dull hillary'",
         "0"
        ],
        [
         "13",
         "actually, cnn's jeffrey lord has been 'indefensible' for a while",
         "0"
        ],
        [
         "14",
         "barcelona holds huge protest in support of refugees",
         "0"
        ],
        [
         "15",
         "nuclear bomb detonates during rehearsal for 'spider-man' musical",
         "1"
        ],
        [
         "16",
         "cosby lawyer asks why accusers didn't come forward to be smeared by legal team years ago",
         "1"
        ],
        [
         "17",
         "stock analysts confused, frightened by boar market",
         "1"
        ],
        [
         "18",
         "bloomberg's program to build better cities just got bigger",
         "0"
        ],
        [
         "19",
         "craig hicks indicted",
         "0"
        ],
        [
         "20",
         "courtroom sketch artist has clear manga influences",
         "1"
        ],
        [
         "21",
         "trump assures nation that decision for syrian airstrikes came after carefully considering all his passing whims",
         "1"
        ],
        [
         "22",
         "qatar deporting dutch woman who reported she was drugged and raped",
         "0"
        ],
        [
         "23",
         "this is why you shouldn't go to the circus",
         "0"
        ],
        [
         "24",
         "ted cruz hits the panic button: 'we could lose both houses of congress'",
         "0"
        ],
        [
         "25",
         "why writers must plan to be surprised",
         "0"
        ],
        [
         "26",
         "obama visits arlington national cemetery to honor veterans",
         "0"
        ],
        [
         "27",
         "ex-con back behind bar",
         "1"
        ],
        [
         "28",
         "after careful consideration, bush recommends oil drilling",
         "1"
        ],
        [
         "29",
         "remembrance is the beginning of the task",
         "0"
        ],
        [
         "30",
         "allies: islamist motive for killing nemtsov is nonsense",
         "0"
        ],
        [
         "31",
         "gillian jacobs on what it's like to kiss adam brody",
         "0"
        ],
        [
         "32",
         "uber vows to repay nyc drivers 'tens of millions' after tax snafu",
         "0"
        ],
        [
         "33",
         "apple may have poached electric motorcycle company to death",
         "0"
        ],
        [
         "34",
         "drug-resistant bacteria often lurk in children's, dogs' sandboxes",
         "0"
        ],
        [
         "35",
         "if you see a muslim at the airport",
         "0"
        ],
        [
         "36",
         "giant altoid heading toward earth",
         "1"
        ],
        [
         "37",
         "'moana' sails straight to the top of the box office with massive $81.1 million opening",
         "0"
        ],
        [
         "38",
         "selig counted money while baseball lost the next generation of fans",
         "0"
        ],
        [
         "39",
         "robin williams inflicted on holiday moviegoers for eighth straight year",
         "1"
        ],
        [
         "40",
         "devin nunes vows to 'never' reveal source of surveillance claims",
         "0"
        ],
        [
         "41",
         "scott used to stop breathing nearly 40 times an hour. this device changed his life",
         "0"
        ],
        [
         "42",
         "rescuers heroically help beached garbage back into ocean",
         "1"
        ],
        [
         "43",
         "medics drop soccer player from stretcher; he's ticked",
         "0"
        ],
        [
         "44",
         "give the gift of play this holiday season",
         "0"
        ],
        [
         "45",
         "christian bale visits sikh temple victims",
         "1"
        ],
        [
         "46",
         "spicer denies that ending maternity care guarantee would mean women pay more for health care",
         "0"
        ],
        [
         "47",
         "'right to live life in complete, stunned horror,' added to constitution",
         "1"
        ],
        [
         "48",
         "nasa now almost positive mars is rocky",
         "1"
        ],
        [
         "49",
         "monster undeterred by night-light",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 26709
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26704</th>\n",
       "      <td>american politics in moral free-fall</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26705</th>\n",
       "      <td>america's best 20 hikes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26706</th>\n",
       "      <td>reparations and obama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26707</th>\n",
       "      <td>israeli ban targeting boycott supporters raise...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26708</th>\n",
       "      <td>gourmet gifts for the foodie 2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26709 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  is_sarcastic\n",
       "0      former versace store clerk sues over secret 'b...             0\n",
       "1      the 'roseanne' revival catches up to our thorn...             0\n",
       "2      mom starting to fear son's web series closest ...             1\n",
       "3      boehner just wants wife to listen, not come up...             1\n",
       "4      j.k. rowling wishes snape happy birthday in th...             0\n",
       "...                                                  ...           ...\n",
       "26704               american politics in moral free-fall             0\n",
       "26705                            america's best 20 hikes             0\n",
       "26706                              reparations and obama             0\n",
       "26707  israeli ban targeting boycott supporters raise...             0\n",
       "26708                  gourmet gifts for the foodie 2014             0\n",
       "\n",
       "[26709 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ea2d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(np.array(data_df['headline']), np.array(data_df['is_sarcastic']), test_size=0.3)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73a1ac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18696,) (18696,)\n",
      "(4006,) (4006,)\n",
      "(4007,) (4007,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30fd90bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')\n",
    "bert_model = AutoModel.from_pretrained('google-bert/bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f20a688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, text, labels, tokenizer, max_len = 100):\n",
    "        \n",
    "        self.encodings = tokenizer(\n",
    "            text,\n",
    "            max_length=max_len,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "    \n",
    "training_dataset = dataset(x_train.tolist(), y_train.tolist(), tokenizer)\n",
    "val_dataset = dataset(x_val.tolist(), y_val.tolist(), tokenizer)\n",
    "test_dataset = dataset(x_test.tolist(), y_test.tolist(), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "545e207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05a139ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=training_dataset, batch_size = batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size = batch_size)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64708143",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(NN, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.linear1 = nn.Linear(768, 384)\n",
    "        self.linear2 = nn.Linear(384, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        pooled_output = self.bert(input_ids, attention_mask, return_dict = False)[0][:,0]\n",
    "        output = self.linear1(pooled_output)\n",
    "        output = self.dropout(output)\n",
    "        output = self.linear2(output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61990a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in bert_model.parameters():\n",
    "    params.requires_grad = True\n",
    "model = NN(bert_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4638081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       "  (linear1): Linear(in_features=768, out_features=384, bias=True)\n",
       "  (linear2): Linear(in_features=384, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6852ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a185ef2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m loss.backward()\n\u001b[32m     21\u001b[39m optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m total_loss_train += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m preds = (outputs > \u001b[32m0.5\u001b[39m).long()\n\u001b[32m     25\u001b[39m total_acc_train += (preds == labels.long()).sum().item()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "total_loss_training_plot = []\n",
    "total_loss_val_plot = []\n",
    "total_acc_training_plot = []\n",
    "total_acc_val_plot = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss_train = 0\n",
    "    total_acc_train = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask).squeeze(1)  # [batch]\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss_train += loss.item()\n",
    "        preds = (outputs > 0.5).long()\n",
    "        total_acc_train += (preds == labels.long()).sum().item()\n",
    "\n",
    "    model.eval()\n",
    "    total_loss_val = 0\n",
    "    total_acc_val = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device).float()\n",
    "\n",
    "            outputs = model(input_ids, attention_mask).squeeze(1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss_val += loss.item()\n",
    "            preds = (outputs > 0.5).long()\n",
    "            total_acc_val += (preds == labels.long()).sum().item()\n",
    "\n",
    "    avg_train_loss = total_loss_train / len(train_loader)\n",
    "    avg_train_acc = total_acc_train / len(training_dataset)\n",
    "    avg_val_loss = total_loss_val / len(val_loader)\n",
    "    avg_val_acc = total_acc_val / len(val_dataset)\n",
    "\n",
    "    total_loss_training_plot.append(avg_train_loss)\n",
    "    total_acc_training_plot.append(avg_train_acc)\n",
    "    total_loss_val_plot.append(avg_val_loss)\n",
    "    total_acc_val_plot.append(avg_val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f40934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
