{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a27c6388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4359fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34232b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Area",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MajorAxisLength",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MinorAxisLength",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Eccentricity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ConvexArea",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EquivDiameter",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Extent",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Perimeter",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Roundness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AspectRation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Class",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2c0da933-a127-445d-beca-58acab91115a",
       "rows": [
        [
         "0",
         "1",
         "4537",
         "92.2293165",
         "64.01276874",
         "0.7199162256",
         "4677",
         "76.00452496",
         "0.6575362319",
         "273.085",
         "0.7645096145",
         "1.440795615",
         "1"
        ],
        [
         "1",
         "2",
         "2872",
         "74.69188071",
         "51.40045446",
         "0.7255527468",
         "3015",
         "60.47101762",
         "0.7130089374",
         "208.317",
         "0.8316582009",
         "1.453136582",
         "1"
        ],
        [
         "2",
         "3",
         "3048",
         "76.2931638",
         "52.04349114",
         "0.7312109273",
         "3132",
         "62.29634124",
         "0.7591531756",
         "210.012",
         "0.8684335737",
         "1.465950153",
         "1"
        ],
        [
         "3",
         "4",
         "3073",
         "77.03362772",
         "51.92848667",
         "0.7386386945",
         "3157",
         "62.55129991",
         "0.7835288118",
         "210.657",
         "0.8702031163",
         "1.48345605",
         "1"
        ],
        [
         "4",
         "5",
         "3693",
         "85.12478457",
         "56.37402054",
         "0.7492815788",
         "3802",
         "68.5716679",
         "0.769375",
         "230.332",
         "0.8747432792",
         "1.51000024",
         "1"
        ],
        [
         "5",
         "6",
         "2990",
         "77.41707342",
         "50.9543441",
         "0.7528608886",
         "3080",
         "61.70077989",
         "0.5848982786",
         "216.93",
         "0.798439143",
         "1.519341968",
         "1"
        ],
        [
         "6",
         "7",
         "3556",
         "84.32356418",
         "55.41306133",
         "0.7537615734",
         "3636",
         "67.28773901",
         "0.7502109705",
         "227.007",
         "0.8671477822",
         "1.521727227",
         "1"
        ],
        [
         "7",
         "8",
         "3788",
         "86.95241143",
         "56.44476861",
         "0.7606642424",
         "3866",
         "69.44804818",
         "0.8006763898",
         "235.476",
         "0.8584727903",
         "1.540486631",
         "1"
        ],
        [
         "8",
         "9",
         "2629",
         "74.13311404",
         "48.07414422",
         "0.7612282171",
         "2790",
         "57.8562595",
         "0.6405945419",
         "207.325",
         "0.7685941985",
         "1.542057903",
         "1"
        ],
        [
         "9",
         "10",
         "5719",
         "106.7211415",
         "68.97769987",
         "0.7630530565",
         "5819",
         "85.33262539",
         "0.7549834983",
         "281.839",
         "0.9047483132",
         "1.547183245",
         "1"
        ],
        [
         "10",
         "11",
         "2665",
         "74.36402121",
         "48.05318758",
         "0.7631777049",
         "2777",
         "58.25103765",
         "0.5967308554",
         "202.456",
         "0.8170446174",
         "1.547535657",
         "1"
        ],
        [
         "11",
         "12",
         "3231",
         "81.3042004",
         "52.4511359",
         "0.7640795022",
         "3330",
         "64.13919994",
         "0.6149600305",
         "218.773",
         "0.8483193583",
         "1.550094178",
         "1"
        ],
        [
         "12",
         "13",
         "2805",
         "77.04768244",
         "49.24267814",
         "0.7691074267",
         "2950",
         "59.76150034",
         "0.6032258065",
         "209.823",
         "0.8006386387",
         "1.564652561",
         "1"
        ],
        [
         "13",
         "14",
         "3265",
         "83.37848692",
         "52.76486452",
         "0.7742862903",
         "3420",
         "64.47578703",
         "0.5758377425",
         "227.853",
         "0.7902846518",
         "1.580189539",
         "1"
        ],
        [
         "14",
         "15",
         "4301",
         "94.91539197",
         "59.82281961",
         "0.7763717836",
         "4427",
         "74.00137351",
         "0.8012295082",
         "257.607",
         "0.8144491728",
         "1.586608465",
         "1"
        ],
        [
         "15",
         "16",
         "3393",
         "84.05848002",
         "52.95148583",
         "0.7766468237",
         "3477",
         "65.72748113",
         "0.6885146104",
         "224.485",
         "0.8460948855",
         "1.587462159",
         "1"
        ],
        [
         "16",
         "17",
         "3475",
         "84.58114773",
         "53.1912048",
         "0.7775041685",
         "3539",
         "66.5169709",
         "0.6522147147",
         "221.295",
         "0.8917055506",
         "1.590134084",
         "1"
        ],
        [
         "17",
         "18",
         "4577",
         "98.35854914",
         "60.7533301",
         "0.7864357544",
         "4652",
         "76.33883282",
         "0.5917259211",
         "259.184",
         "0.8561983771",
         "1.618982021",
         "1"
        ],
        [
         "18",
         "19",
         "3028",
         "81.27755239",
         "49.16736189",
         "0.7962774192",
         "3114",
         "62.09162054",
         "0.7536087606",
         "211.667",
         "0.849296679",
         "1.653079386",
         "1"
        ],
        [
         "19",
         "20",
         "3552",
         "88.02937756",
         "53.17603697",
         "0.7969301343",
         "3654",
         "67.24988374",
         "0.6237050044",
         "232.122",
         "0.8284193098",
         "1.65543321",
         "1"
        ],
        [
         "20",
         "21",
         "3852",
         "92.20828955",
         "55.27701192",
         "0.8003898458",
         "4023",
         "70.03226918",
         "0.6539898132",
         "245.517",
         "0.8030322832",
         "1.668112772",
         "1"
        ],
        [
         "21",
         "22",
         "3163",
         "83.82327008",
         "50.02465547",
         "0.8023995427",
         "3232",
         "63.46067034",
         "0.5844419808",
         "221.38",
         "0.8110213549",
         "1.675639128",
         "1"
        ],
        [
         "22",
         "23",
         "3910",
         "92.58932307",
         "55.11140291",
         "0.803559698",
         "4067",
         "70.5575412",
         "0.622809812",
         "252.523",
         "0.770521464",
         "1.680039305",
         "1"
        ],
        [
         "23",
         "24",
         "3505",
         "88.0017938",
         "52.27703901",
         "0.8044316982",
         "3586",
         "66.80347749",
         "0.59477346",
         "229.044",
         "0.8395760615",
         "1.683373724",
         "1"
        ],
        [
         "24",
         "25",
         "2647",
         "76.78904267",
         "45.52911212",
         "0.8052675741",
         "2710",
         "58.05398414",
         "0.5981920904",
         "200.587",
         "0.8267196097",
         "1.686592141",
         "1"
        ],
        [
         "25",
         "26",
         "3606",
         "88.77990424",
         "52.5886165",
         "0.8056820772",
         "3658",
         "67.7591455",
         "0.5930921053",
         "227.906",
         "0.8724168976",
         "1.688196232",
         "1"
        ],
        [
         "26",
         "27",
         "4136",
         "95.74362731",
         "56.41101106",
         "0.8079958656",
         "4217",
         "72.56802848",
         "0.7659259259",
         "247.294",
         "0.84989101",
         "1.697250688",
         "1"
        ],
        [
         "27",
         "28",
         "3951",
         "94.12263105",
         "55.39145755",
         "0.8084949807",
         "4045",
         "70.92650732",
         "0.6069124424",
         "247.032",
         "0.8135991098",
         "1.699226473",
         "1"
        ],
        [
         "28",
         "29",
         "3867",
         "92.47994738",
         "54.37937746",
         "0.808851743",
         "3960",
         "70.16849236",
         "0.7812121212",
         "240.315",
         "0.8414383021",
         "1.700643731",
         "1"
        ],
        [
         "29",
         "30",
         "3177",
         "84.54078476",
         "49.52659704",
         "0.8104333738",
         "3247",
         "63.60095938",
         "0.8171296296",
         "219.663",
         "0.8273956965",
         "1.706977459",
         "1"
        ],
        [
         "30",
         "31",
         "3987",
         "94.17620603",
         "54.94802805",
         "0.8121420382",
         "4043",
         "71.2489022",
         "0.5943649374",
         "240.915",
         "0.8632337613",
         "1.713914209",
         "1"
        ],
        [
         "31",
         "32",
         "4038",
         "95.2470937",
         "55.21937217",
         "0.8147953884",
         "4126",
         "71.70314694",
         "0.6361058601",
         "244.287",
         "0.8503064362",
         "1.724885488",
         "1"
        ],
        [
         "32",
         "33",
         "3426",
         "88.92210563",
         "51.48838799",
         "0.8153076647",
         "3548",
         "66.04633737",
         "0.563208943",
         "232.94",
         "0.7934308459",
         "1.727032232",
         "1"
        ],
        [
         "33",
         "34",
         "3938",
         "94.26939767",
         "54.30216853",
         "0.8174273016",
         "4009",
         "70.80972622",
         "0.8414529915",
         "238.395",
         "0.8707456047",
         "1.736015342",
         "1"
        ],
        [
         "34",
         "35",
         "3636",
         "91.40038634",
         "52.30281469",
         "0.8200872913",
         "3723",
         "68.0404217",
         "0.7552970503",
         "235.385",
         "0.824662357",
         "1.747523281",
         "1"
        ],
        [
         "35",
         "36",
         "2965",
         "82.57014058",
         "47.15593922",
         "0.8208793851",
         "3068",
         "61.44229203",
         "0.6075819672",
         "214.44",
         "0.8102573226",
         "1.75100193",
         "1"
        ],
        [
         "36",
         "37",
         "3335",
         "87.97830505",
         "50.23674047",
         "0.8209411393",
         "3459",
         "65.1632863",
         "0.625",
         "229.787",
         "0.793697097",
         "1.751274152",
         "1"
        ],
        [
         "37",
         "38",
         "3277",
         "87.3845036",
         "49.64746533",
         "0.8229253324",
         "3408",
         "64.59416373",
         "0.6301923077",
         "227.562",
         "0.7952191342",
         "1.760099997",
         "1"
        ],
        [
         "38",
         "39",
         "3446",
         "89.40212268",
         "50.79059698",
         "0.8229498708",
         "3533",
         "66.23883658",
         "0.8083509266",
         "229.852",
         "0.8196502263",
         "1.760210118",
         "1"
        ],
        [
         "39",
         "40",
         "3697",
         "91.87618278",
         "52.09462225",
         "0.8237115984",
         "3772",
         "68.60879387",
         "0.8498850575",
         "231.291",
         "0.8684440559",
         "1.763640445",
         "1"
        ],
        [
         "40",
         "41",
         "2953",
         "82.87781414",
         "46.99201881",
         "0.8237153148",
         "3043",
         "61.31783081",
         "0.692217534",
         "214.338",
         "0.8077462734",
         "1.763657239",
         "1"
        ],
        [
         "41",
         "42",
         "3670",
         "92.21294021",
         "51.85164606",
         "0.8269310322",
         "3772",
         "68.35780226",
         "0.7369477912",
         "235.534",
         "0.8313209266",
         "1.778399476",
         "1"
        ],
        [
         "42",
         "43",
         "3415",
         "89.49579817",
         "50.31824228",
         "0.8269731648",
         "3534",
         "65.94022327",
         "0.6873993559",
         "232.838",
         "0.7915764255",
         "1.778595478",
         "1"
        ],
        [
         "43",
         "44",
         "3860",
         "94.63650283",
         "53.13975738",
         "0.8274669777",
         "3942",
         "70.10495448",
         "0.8157227388",
         "242.845",
         "0.8225055488",
         "1.780898286",
         "1"
        ],
        [
         "44",
         "45",
         "3271",
         "87.41286344",
         "49.06935374",
         "0.8275773939",
         "3391",
         "64.53500252",
         "0.6713875205",
         "226.793",
         "0.7991551756",
         "1.781414606",
         "1"
        ],
        [
         "45",
         "46",
         "3657",
         "92.43690606",
         "51.86429927",
         "0.8277630466",
         "3725",
         "68.23662517",
         "0.6321521175",
         "234.047",
         "0.8389356829",
         "1.782283909",
         "1"
        ],
        [
         "46",
         "47",
         "3494",
         "90.07527599",
         "50.52519208",
         "0.8278687443",
         "3580",
         "66.69856797",
         "0.7254983389",
         "227.934",
         "0.8451125299",
         "1.782779486",
         "1"
        ],
        [
         "47",
         "48",
         "3899",
         "95.37622831",
         "53.32667827",
         "0.829087297",
         "3977",
         "70.45822156",
         "0.6421277997",
         "240.44",
         "0.8475194244",
         "1.788527458",
         "1"
        ],
        [
         "48",
         "49",
         "2522",
         "77.09079003",
         "42.87187941",
         "0.8311007112",
         "2579",
         "56.66665803",
         "0.5987654321",
         "197.015",
         "0.8165003218",
         "1.798166796",
         "1"
        ],
        [
         "49",
         "50",
         "3812",
         "95.00364795",
         "52.78100382",
         "0.8314709838",
         "3903",
         "69.66770518",
         "0.5965571205",
         "244.123",
         "0.8037951092",
         "1.799959097",
         "1"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 18185
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4537</td>\n",
       "      <td>92.229316</td>\n",
       "      <td>64.012769</td>\n",
       "      <td>0.719916</td>\n",
       "      <td>4677</td>\n",
       "      <td>76.004525</td>\n",
       "      <td>0.657536</td>\n",
       "      <td>273.085</td>\n",
       "      <td>0.764510</td>\n",
       "      <td>1.440796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2872</td>\n",
       "      <td>74.691881</td>\n",
       "      <td>51.400454</td>\n",
       "      <td>0.725553</td>\n",
       "      <td>3015</td>\n",
       "      <td>60.471018</td>\n",
       "      <td>0.713009</td>\n",
       "      <td>208.317</td>\n",
       "      <td>0.831658</td>\n",
       "      <td>1.453137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3048</td>\n",
       "      <td>76.293164</td>\n",
       "      <td>52.043491</td>\n",
       "      <td>0.731211</td>\n",
       "      <td>3132</td>\n",
       "      <td>62.296341</td>\n",
       "      <td>0.759153</td>\n",
       "      <td>210.012</td>\n",
       "      <td>0.868434</td>\n",
       "      <td>1.465950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3073</td>\n",
       "      <td>77.033628</td>\n",
       "      <td>51.928487</td>\n",
       "      <td>0.738639</td>\n",
       "      <td>3157</td>\n",
       "      <td>62.551300</td>\n",
       "      <td>0.783529</td>\n",
       "      <td>210.657</td>\n",
       "      <td>0.870203</td>\n",
       "      <td>1.483456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3693</td>\n",
       "      <td>85.124785</td>\n",
       "      <td>56.374021</td>\n",
       "      <td>0.749282</td>\n",
       "      <td>3802</td>\n",
       "      <td>68.571668</td>\n",
       "      <td>0.769375</td>\n",
       "      <td>230.332</td>\n",
       "      <td>0.874743</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18180</th>\n",
       "      <td>18181</td>\n",
       "      <td>5853</td>\n",
       "      <td>148.624571</td>\n",
       "      <td>51.029281</td>\n",
       "      <td>0.939210</td>\n",
       "      <td>6008</td>\n",
       "      <td>86.326537</td>\n",
       "      <td>0.498594</td>\n",
       "      <td>332.960</td>\n",
       "      <td>0.663444</td>\n",
       "      <td>2.912535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18181</th>\n",
       "      <td>18182</td>\n",
       "      <td>7585</td>\n",
       "      <td>169.593996</td>\n",
       "      <td>58.141659</td>\n",
       "      <td>0.939398</td>\n",
       "      <td>7806</td>\n",
       "      <td>98.272692</td>\n",
       "      <td>0.647461</td>\n",
       "      <td>385.506</td>\n",
       "      <td>0.641362</td>\n",
       "      <td>2.916910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18182</th>\n",
       "      <td>18183</td>\n",
       "      <td>6365</td>\n",
       "      <td>154.777085</td>\n",
       "      <td>52.908085</td>\n",
       "      <td>0.939760</td>\n",
       "      <td>6531</td>\n",
       "      <td>90.023162</td>\n",
       "      <td>0.561287</td>\n",
       "      <td>342.253</td>\n",
       "      <td>0.682832</td>\n",
       "      <td>2.925396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18183</th>\n",
       "      <td>18184</td>\n",
       "      <td>5960</td>\n",
       "      <td>151.397924</td>\n",
       "      <td>51.474600</td>\n",
       "      <td>0.940427</td>\n",
       "      <td>6189</td>\n",
       "      <td>87.112041</td>\n",
       "      <td>0.492399</td>\n",
       "      <td>343.371</td>\n",
       "      <td>0.635227</td>\n",
       "      <td>2.941216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18184</th>\n",
       "      <td>18185</td>\n",
       "      <td>6134</td>\n",
       "      <td>153.081981</td>\n",
       "      <td>51.590606</td>\n",
       "      <td>0.941500</td>\n",
       "      <td>6283</td>\n",
       "      <td>88.374495</td>\n",
       "      <td>0.489975</td>\n",
       "      <td>338.613</td>\n",
       "      <td>0.672274</td>\n",
       "      <td>2.967245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18185 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  Area  MajorAxisLength  ...  Roundness  AspectRation  Class\n",
       "0          1  4537        92.229316  ...   0.764510      1.440796      1\n",
       "1          2  2872        74.691881  ...   0.831658      1.453137      1\n",
       "2          3  3048        76.293164  ...   0.868434      1.465950      1\n",
       "3          4  3073        77.033628  ...   0.870203      1.483456      1\n",
       "4          5  3693        85.124785  ...   0.874743      1.510000      1\n",
       "...      ...   ...              ...  ...        ...           ...    ...\n",
       "18180  18181  5853       148.624571  ...   0.663444      2.912535      0\n",
       "18181  18182  7585       169.593996  ...   0.641362      2.916910      0\n",
       "18182  18183  6365       154.777085  ...   0.682832      2.925396      0\n",
       "18183  18184  5960       151.397924  ...   0.635227      2.941216      0\n",
       "18184  18185  6134       153.081981  ...   0.672274      2.967245      0\n",
       "\n",
       "[18185 rows x 12 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('riceClassification.csv')\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52487b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba9f470f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity',\n",
       "       'ConvexArea', 'EquivDiameter', 'Extent', 'Perimeter', 'Roundness',\n",
       "       'AspectRation', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5532f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = ['Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity',\n",
    "       'ConvexArea', 'EquivDiameter', 'Extent', 'Perimeter', 'Roundness',\n",
    "       'AspectRation']\n",
    "target_cols = 'Class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2659e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df, test_df = train_test_split(data_df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f23822b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(train_df[input_cols])\n",
    "train_df[input_cols] = scaler.transform(train_df[input_cols])\n",
    "val_df[input_cols] = scaler.transform(val_df[input_cols])\n",
    "test_df[input_cols] = scaler.transform(test_df[input_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffd859bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(train_df[input_cols].values, dtype=torch.float32).to(device)\n",
    "x_val = torch.tensor(val_df[input_cols].values, dtype=torch.float32).to(device)\n",
    "x_test = torch.tensor(test_df[input_cols].values, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(train_df[target_cols].values, dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(val_df[target_cols].values, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(test_df[target_cols].values, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96c58b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "val_ds = TensorDataset(x_val, y_val)\n",
    "test_ds = TensorDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd5be6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3cafa291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f2ae8b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[1]\n",
    "hidden_layer = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "322e36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_layer)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(hidden_layer, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "model = MyModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f9f4fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 10]             110\n",
      "              ReLU-2                   [-1, 10]               0\n",
      "            Linear-3                    [-1, 1]              11\n",
      "           Sigmoid-4                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size = (input_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1819d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a597c8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_training_plot = []\n",
    "total_loss_validation_plot = []\n",
    "total_acc_training_plot = []\n",
    "total_acc_validation_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff2727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no. 1 Train Loss: 0.0075 Train Accuracy: 98.6510 Validation Loss: 0.0018 Validation Accuracy: 98.6254\n",
      "==================================================\n",
      "Epoch no. 2 Train Loss: 0.0074 Train Accuracy: 98.6424 Validation Loss: 0.0018 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 3 Train Loss: 0.0074 Train Accuracy: 98.6596 Validation Loss: 0.0018 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 4 Train Loss: 0.0074 Train Accuracy: 98.6080 Validation Loss: 0.0019 Validation Accuracy: 98.6254\n",
      "==================================================\n",
      "Epoch no. 5 Train Loss: 0.0074 Train Accuracy: 98.6166 Validation Loss: 0.0018 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 6 Train Loss: 0.0074 Train Accuracy: 98.6166 Validation Loss: 0.0019 Validation Accuracy: 98.6254\n",
      "==================================================\n",
      "Epoch no. 7 Train Loss: 0.0074 Train Accuracy: 98.6510 Validation Loss: 0.0018 Validation Accuracy: 98.6598\n",
      "==================================================\n",
      "Epoch no. 8 Train Loss: 0.0074 Train Accuracy: 98.6424 Validation Loss: 0.0018 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 9 Train Loss: 0.0074 Train Accuracy: 98.6080 Validation Loss: 0.0019 Validation Accuracy: 98.5911\n",
      "==================================================\n",
      "Epoch no. 10 Train Loss: 0.0073 Train Accuracy: 98.6682 Validation Loss: 0.0018 Validation Accuracy: 98.6254\n",
      "==================================================\n",
      "Epoch no. 11 Train Loss: 0.0073 Train Accuracy: 98.6424 Validation Loss: 0.0019 Validation Accuracy: 98.6942\n",
      "==================================================\n",
      "Epoch no. 12 Train Loss: 0.0073 Train Accuracy: 98.6767 Validation Loss: 0.0018 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 13 Train Loss: 0.0073 Train Accuracy: 98.6510 Validation Loss: 0.0018 Validation Accuracy: 98.6942\n",
      "==================================================\n",
      "Epoch no. 14 Train Loss: 0.0073 Train Accuracy: 98.6424 Validation Loss: 0.0018 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 15 Train Loss: 0.0073 Train Accuracy: 98.6596 Validation Loss: 0.0018 Validation Accuracy: 98.6942\n",
      "==================================================\n",
      "Epoch no. 16 Train Loss: 0.0073 Train Accuracy: 98.6252 Validation Loss: 0.0018 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 17 Train Loss: 0.0073 Train Accuracy: 98.6338 Validation Loss: 0.0018 Validation Accuracy: 98.5911\n",
      "==================================================\n",
      "Epoch no. 18 Train Loss: 0.0073 Train Accuracy: 98.6424 Validation Loss: 0.0018 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 19 Train Loss: 0.0072 Train Accuracy: 98.6939 Validation Loss: 0.0018 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 20 Train Loss: 0.0072 Train Accuracy: 98.6080 Validation Loss: 0.0018 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 21 Train Loss: 0.0072 Train Accuracy: 98.6853 Validation Loss: 0.0019 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 22 Train Loss: 0.0072 Train Accuracy: 98.6424 Validation Loss: 0.0018 Validation Accuracy: 98.6598\n",
      "==================================================\n",
      "Epoch no. 23 Train Loss: 0.0073 Train Accuracy: 98.6767 Validation Loss: 0.0018 Validation Accuracy: 98.6942\n",
      "==================================================\n",
      "Epoch no. 24 Train Loss: 0.0072 Train Accuracy: 98.6767 Validation Loss: 0.0018 Validation Accuracy: 98.6942\n",
      "==================================================\n",
      "Epoch no. 25 Train Loss: 0.0072 Train Accuracy: 98.6596 Validation Loss: 0.0019 Validation Accuracy: 98.5567\n",
      "==================================================\n",
      "Epoch no. 26 Train Loss: 0.0072 Train Accuracy: 98.6682 Validation Loss: 0.0018 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 27 Train Loss: 0.0072 Train Accuracy: 98.6939 Validation Loss: 0.0018 Validation Accuracy: 98.6942\n",
      "==================================================\n",
      "Epoch no. 28 Train Loss: 0.0072 Train Accuracy: 98.7111 Validation Loss: 0.0018 Validation Accuracy: 98.6942\n",
      "==================================================\n",
      "Epoch no. 29 Train Loss: 0.0071 Train Accuracy: 98.7197 Validation Loss: 0.0018 Validation Accuracy: 98.6942\n",
      "==================================================\n",
      "Epoch no. 30 Train Loss: 0.0071 Train Accuracy: 98.7025 Validation Loss: 0.0018 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 31 Train Loss: 0.0071 Train Accuracy: 98.6682 Validation Loss: 0.0018 Validation Accuracy: 98.6942\n",
      "==================================================\n",
      "Epoch no. 32 Train Loss: 0.0071 Train Accuracy: 98.7197 Validation Loss: 0.0018 Validation Accuracy: 98.6942\n",
      "==================================================\n",
      "Epoch no. 33 Train Loss: 0.0071 Train Accuracy: 98.6767 Validation Loss: 0.0018 Validation Accuracy: 98.6598\n",
      "==================================================\n",
      "Epoch no. 34 Train Loss: 0.0071 Train Accuracy: 98.6853 Validation Loss: 0.0018 Validation Accuracy: 98.5567\n",
      "==================================================\n",
      "Epoch no. 35 Train Loss: 0.0071 Train Accuracy: 98.7111 Validation Loss: 0.0018 Validation Accuracy: 98.6254\n",
      "==================================================\n",
      "Epoch no. 36 Train Loss: 0.0071 Train Accuracy: 98.7455 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 37 Train Loss: 0.0071 Train Accuracy: 98.6939 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 38 Train Loss: 0.0071 Train Accuracy: 98.7627 Validation Loss: 0.0018 Validation Accuracy: 98.6598\n",
      "==================================================\n",
      "Epoch no. 39 Train Loss: 0.0071 Train Accuracy: 98.7541 Validation Loss: 0.0020 Validation Accuracy: 98.6254\n",
      "==================================================\n",
      "Epoch no. 40 Train Loss: 0.0070 Train Accuracy: 98.7799 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 41 Train Loss: 0.0070 Train Accuracy: 98.7369 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 42 Train Loss: 0.0070 Train Accuracy: 98.7541 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 43 Train Loss: 0.0070 Train Accuracy: 98.7369 Validation Loss: 0.0018 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 44 Train Loss: 0.0070 Train Accuracy: 98.7369 Validation Loss: 0.0017 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 45 Train Loss: 0.0070 Train Accuracy: 98.7885 Validation Loss: 0.0018 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 46 Train Loss: 0.0070 Train Accuracy: 98.7541 Validation Loss: 0.0018 Validation Accuracy: 98.6942\n",
      "==================================================\n",
      "Epoch no. 47 Train Loss: 0.0070 Train Accuracy: 98.7541 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 48 Train Loss: 0.0070 Train Accuracy: 98.7283 Validation Loss: 0.0017 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 49 Train Loss: 0.0070 Train Accuracy: 98.7111 Validation Loss: 0.0017 Validation Accuracy: 98.6942\n",
      "==================================================\n",
      "Epoch no. 50 Train Loss: 0.0070 Train Accuracy: 98.7283 Validation Loss: 0.0017 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 51 Train Loss: 0.0070 Train Accuracy: 98.7799 Validation Loss: 0.0017 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 52 Train Loss: 0.0069 Train Accuracy: 98.7627 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 53 Train Loss: 0.0069 Train Accuracy: 98.7541 Validation Loss: 0.0017 Validation Accuracy: 98.7973\n",
      "==================================================\n",
      "Epoch no. 54 Train Loss: 0.0069 Train Accuracy: 98.7713 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 55 Train Loss: 0.0069 Train Accuracy: 98.7885 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 56 Train Loss: 0.0069 Train Accuracy: 98.7970 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 57 Train Loss: 0.0069 Train Accuracy: 98.7799 Validation Loss: 0.0017 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 58 Train Loss: 0.0069 Train Accuracy: 98.7970 Validation Loss: 0.0017 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 59 Train Loss: 0.0069 Train Accuracy: 98.7627 Validation Loss: 0.0017 Validation Accuracy: 98.8316\n",
      "==================================================\n",
      "Epoch no. 60 Train Loss: 0.0069 Train Accuracy: 98.7627 Validation Loss: 0.0017 Validation Accuracy: 98.8316\n",
      "==================================================\n",
      "Epoch no. 61 Train Loss: 0.0068 Train Accuracy: 98.8228 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 62 Train Loss: 0.0068 Train Accuracy: 98.8314 Validation Loss: 0.0017 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 63 Train Loss: 0.0068 Train Accuracy: 98.8228 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 64 Train Loss: 0.0068 Train Accuracy: 98.8228 Validation Loss: 0.0018 Validation Accuracy: 98.7973\n",
      "==================================================\n",
      "Epoch no. 65 Train Loss: 0.0068 Train Accuracy: 98.8056 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 66 Train Loss: 0.0068 Train Accuracy: 98.8056 Validation Loss: 0.0017 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 67 Train Loss: 0.0069 Train Accuracy: 98.7713 Validation Loss: 0.0017 Validation Accuracy: 98.6598\n",
      "==================================================\n",
      "Epoch no. 68 Train Loss: 0.0068 Train Accuracy: 98.8572 Validation Loss: 0.0017 Validation Accuracy: 98.7973\n",
      "==================================================\n",
      "Epoch no. 69 Train Loss: 0.0068 Train Accuracy: 98.8486 Validation Loss: 0.0017 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 70 Train Loss: 0.0068 Train Accuracy: 98.8486 Validation Loss: 0.0017 Validation Accuracy: 98.7973\n",
      "==================================================\n",
      "Epoch no. 71 Train Loss: 0.0068 Train Accuracy: 98.7970 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 72 Train Loss: 0.0068 Train Accuracy: 98.8142 Validation Loss: 0.0017 Validation Accuracy: 98.7973\n",
      "==================================================\n",
      "Epoch no. 73 Train Loss: 0.0067 Train Accuracy: 98.8486 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 74 Train Loss: 0.0068 Train Accuracy: 98.8658 Validation Loss: 0.0017 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 75 Train Loss: 0.0067 Train Accuracy: 98.8142 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 76 Train Loss: 0.0068 Train Accuracy: 98.8228 Validation Loss: 0.0017 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 77 Train Loss: 0.0067 Train Accuracy: 98.8572 Validation Loss: 0.0017 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 78 Train Loss: 0.0067 Train Accuracy: 98.8400 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 79 Train Loss: 0.0067 Train Accuracy: 98.8916 Validation Loss: 0.0017 Validation Accuracy: 98.7973\n",
      "==================================================\n",
      "Epoch no. 80 Train Loss: 0.0067 Train Accuracy: 98.8486 Validation Loss: 0.0017 Validation Accuracy: 98.7973\n",
      "==================================================\n",
      "Epoch no. 81 Train Loss: 0.0067 Train Accuracy: 98.8658 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 82 Train Loss: 0.0067 Train Accuracy: 98.8658 Validation Loss: 0.0017 Validation Accuracy: 98.6942\n",
      "==================================================\n",
      "Epoch no. 83 Train Loss: 0.0067 Train Accuracy: 98.9087 Validation Loss: 0.0017 Validation Accuracy: 98.7973\n",
      "==================================================\n",
      "Epoch no. 84 Train Loss: 0.0066 Train Accuracy: 98.8228 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 85 Train Loss: 0.0066 Train Accuracy: 98.8658 Validation Loss: 0.0017 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 86 Train Loss: 0.0066 Train Accuracy: 98.9087 Validation Loss: 0.0017 Validation Accuracy: 98.7973\n",
      "==================================================\n",
      "Epoch no. 87 Train Loss: 0.0067 Train Accuracy: 98.7970 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 88 Train Loss: 0.0066 Train Accuracy: 98.8572 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 89 Train Loss: 0.0066 Train Accuracy: 98.8658 Validation Loss: 0.0017 Validation Accuracy: 98.7973\n",
      "==================================================\n",
      "Epoch no. 90 Train Loss: 0.0066 Train Accuracy: 98.8658 Validation Loss: 0.0017 Validation Accuracy: 98.7973\n",
      "==================================================\n",
      "Epoch no. 91 Train Loss: 0.0066 Train Accuracy: 98.9087 Validation Loss: 0.0017 Validation Accuracy: 98.6942\n",
      "==================================================\n",
      "Epoch no. 92 Train Loss: 0.0066 Train Accuracy: 98.8744 Validation Loss: 0.0017 Validation Accuracy: 98.7973\n",
      "==================================================\n",
      "Epoch no. 93 Train Loss: 0.0066 Train Accuracy: 98.8658 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 94 Train Loss: 0.0066 Train Accuracy: 98.9173 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n",
      "Epoch no. 95 Train Loss: 0.0066 Train Accuracy: 98.8400 Validation Loss: 0.0017 Validation Accuracy: 98.7973\n",
      "==================================================\n",
      "Epoch no. 96 Train Loss: 0.0066 Train Accuracy: 98.9087 Validation Loss: 0.0017 Validation Accuracy: 98.7973\n",
      "==================================================\n",
      "Epoch no. 97 Train Loss: 0.0066 Train Accuracy: 98.9087 Validation Loss: 0.0017 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 98 Train Loss: 0.0066 Train Accuracy: 98.9087 Validation Loss: 0.0017 Validation Accuracy: 98.7285\n",
      "==================================================\n",
      "Epoch no. 99 Train Loss: 0.0066 Train Accuracy: 98.9173 Validation Loss: 0.0017 Validation Accuracy: 98.7973\n",
      "==================================================\n",
      "Epoch no. 100 Train Loss: 0.0065 Train Accuracy: 98.9002 Validation Loss: 0.0017 Validation Accuracy: 98.7629\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    total_acc_train = 0\n",
    "    total_acc_val = 0\n",
    "    total_loss_train = 0\n",
    "    total_loss_val = 0\\\n",
    "        \n",
    "    for data in train_loader:\n",
    "        \n",
    "        inputs, labels = data\n",
    "        \n",
    "        prediction = model(inputs).squeeze(1)\n",
    "        \n",
    "        loss = criterion(prediction, labels)\n",
    "        \n",
    "        total_loss_train += loss.item()\n",
    "        \n",
    "        acc = ((prediction).round() == labels).sum().item()\n",
    "        \n",
    "        total_acc_train += acc\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            inputs, labels = data\n",
    "            \n",
    "            val_pred = model(inputs).squeeze(1)\n",
    "            \n",
    "            loss = criterion(val_pred, labels)\n",
    "            \n",
    "            total_loss_val += loss.item()\n",
    "\n",
    "            acc = ((val_pred).round() == labels).sum().item()\n",
    "\n",
    "            total_acc_val += acc\n",
    "        \n",
    "    total_loss_training_plot.append(round(total_loss_train / 1000, 4))\n",
    "    total_loss_validation_plot.append(round(total_loss_val / 1000, 4))\n",
    "    total_acc_training_plot.append(round(total_acc_train / train_ds.__len__() * 100, 4))\n",
    "    total_acc_validation_plot.append(round(total_loss_val / val_ds.__len__() * 100, 4))\n",
    "\n",
    "    \n",
    "    print(f'''Epoch no. {epoch + 1} Train Loss: {total_loss_train/1000:.4f} Train Accuracy: {(total_acc_train/(train_ds.__len__())*100):.4f} Validation Loss: {total_loss_val/1000:.4f} Validation Accuracy: {(total_acc_val/(val_ds.__len__())*100):.4f}''')\n",
    "    print(\"=\"*50)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4898e9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.71%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total_loss_test = 0\n",
    "    total_acc_test = 0\n",
    "    \n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        test_pred = model(inputs).squeeze(1)\n",
    "        \n",
    "        loss = criterion(test_pred, labels)\n",
    "        \n",
    "        total_loss_test += loss.item()\n",
    "        \n",
    "        acc = ((test_pred).round() == labels).sum().item()\n",
    "        \n",
    "        total_acc_test += acc        \n",
    "accuracy = total_acc_test / len(test_ds) * 100\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a523f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08feee3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
